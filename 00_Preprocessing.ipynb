{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f72ad-ef83-4494-bd6a-80d48447b8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando EEG:   0%|‚ñè                                                               | 1/290 [00:30<2:29:02, 30.94s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 136\u001b[39m\n\u001b[32m    133\u001b[39m         extract_random_segments_from_eeg(edf_path)\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 133\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    130\u001b[39m edf_path = os.path.join(data_folder, base + edf_ext)\n\u001b[32m    132\u001b[39m extract_clean_segments_from_eeg(edf_path, ann_df)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43mextract_random_segments_from_eeg\u001b[49m\u001b[43m(\u001b[49m\u001b[43medf_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 114\u001b[39m, in \u001b[36mextract_random_segments_from_eeg\u001b[39m\u001b[34m(edf_path, n_segments, segment_samples)\u001b[39m\n\u001b[32m    112\u001b[39m start = random.randint(\u001b[32m0\u001b[39m, total_samples - segment_samples)\n\u001b[32m    113\u001b[39m stop = start + segment_samples\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m data = \u001b[43mraw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m signal = data.flatten()  \u001b[38;5;66;03m# vector 1D (segment_samples,)\u001b[39;00m\n\u001b[32m    116\u001b[39m fname = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrandom_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchannel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstop\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pt\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-190>:12\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, picks, start, stop, reject_by_annotation, return_times, units, tmin, tmax, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mne\\io\\base.py:965\u001b[39m, in \u001b[36mBaseRaw.get_data\u001b[39m\u001b[34m(self, picks, start, stop, reject_by_annotation, return_times, units, tmin, tmax, verbose)\u001b[39m\n\u001b[32m    962\u001b[39m picks = np.atleast_1d(np.arange(\u001b[38;5;28mself\u001b[39m.info[\u001b[33m\"\u001b[39m\u001b[33mnchan\u001b[39m\u001b[33m\"\u001b[39m])[picks])\n\u001b[32m    964\u001b[39m \u001b[38;5;66;03m# handle start/tmin stop/tmax\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m tmin_start, tmax_stop = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_tmin_tmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmax\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[38;5;66;03m# tmin/tmax are ignored if start/stop are defined to\u001b[39;00m\n\u001b[32m    968\u001b[39m \u001b[38;5;66;03m# something other than their defaults\u001b[39;00m\n\u001b[32m    969\u001b[39m start = tmin_start \u001b[38;5;28;01mif\u001b[39;00m start == \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mne\\utils\\mixin.py:555\u001b[39m, in \u001b[36mTimeMixin._handle_tmin_tmax\u001b[39m\u001b[34m(self, tmin, tmax)\u001b[39m\n\u001b[32m    547\u001b[39m _validate_type(\n\u001b[32m    548\u001b[39m     tmax,\n\u001b[32m    549\u001b[39m     types=(\u001b[33m\"\u001b[39m\u001b[33mnumeric\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    550\u001b[39m     item_name=\u001b[33m\"\u001b[39m\u001b[33mtmax\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    551\u001b[39m     type_name=\u001b[33m\"\u001b[39m\u001b[33mint, float, None\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    552\u001b[39m )\n\u001b[32m    554\u001b[39m \u001b[38;5;66;03m# handle tmin/tmax as start and stop indices into data array\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m555\u001b[39m n_times = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimes\u001b[49m.size\n\u001b[32m    556\u001b[39m start = \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tmin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.time_as_index(tmin)[\u001b[32m0\u001b[39m]\n\u001b[32m    557\u001b[39m stop = n_times \u001b[38;5;28;01mif\u001b[39;00m tmax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.time_as_index(tmax)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mne\\io\\base.py:1989\u001b[39m, in \u001b[36mBaseRaw.times\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1986\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   1987\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtimes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1988\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Time points.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1989\u001b[39m     out = \u001b[43m_arange_div\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msfreq\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1990\u001b[39m     out.flags[\u001b[33m\"\u001b[39m\u001b[33mWRITEABLE\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1991\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numba\\core\\serialize.py:30\u001b[39m, in \u001b[36m_numba_unpickle\u001b[39m\u001b[34m(address, bytedata, hashed)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Keep unpickled object via `numba_unpickle` alive.\u001b[39;00m\n\u001b[32m     27\u001b[39m _unpickled_memo = {}\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_numba_unpickle\u001b[39m(address, bytedata, hashed):\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Used by `numba_unpickle` from _helperlib.c\u001b[39;00m\n\u001b[32m     32\u001b[39m \n\u001b[32m     33\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m \u001b[33;03m        unpickled object\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     44\u001b[39m     key = (address, hashed)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_folder = './v3.0.1/edf/01_tcp_ar'\n",
    "features_path = './features'\n",
    "clean_eeg_path = os.path.join(features_path, 'clean_eeg')\n",
    "random_seg_path = os.path.join(features_path, 'random_segment')\n",
    "csv_ext = '.csv'\n",
    "edf_ext = '.edf'\n",
    "\n",
    "n_random_segments = 5000\n",
    "segment_samples = 5000\n",
    "\n",
    "channel_mapping = {\n",
    "    'EEG FP1-REF': 'FP1', 'EEG FP2-REF': 'FP2',\n",
    "    'EEG F3-REF': 'F3', 'EEG F4-REF': 'F4',\n",
    "    'EEG C3-REF': 'C3', 'EEG C4-REF': 'C4',\n",
    "    'EEG P3-REF': 'P3', 'EEG P4-REF': 'P4',\n",
    "    'EEG O1-REF': 'O1', 'EEG O2-REF': 'O2',\n",
    "    'EEG F7-REF': 'F7', 'EEG F8-REF': 'F8',\n",
    "    'EEG T3-REF': 'T3', 'EEG T4-REF': 'T4',\n",
    "    'EEG T5-REF': 'T5', 'EEG T6-REF': 'T6',\n",
    "    'EEG FZ-REF': 'FZ', 'EEG CZ-REF': 'CZ',\n",
    "    'EEG PZ-REF': 'PZ'\n",
    "}\n",
    "\n",
    "\n",
    "def get_annotations_for_eeg_artifacts(path_root, file_name):\n",
    "    return pd.read_csv(os.path.join(path_root, file_name), skiprows=6)\n",
    "\n",
    "\n",
    "def extract_clean_segments_from_eeg(edf_path, annotations_df,\n",
    "                                   segment_duration=5.0,\n",
    "                                   max_segments_per_interval=None):\n",
    "    raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "\n",
    "    chans = [ch for ch in raw.ch_names if ch in channel_mapping]\n",
    "    raw.pick(chans)\n",
    "    raw.rename_channels(channel_mapping)\n",
    "\n",
    "    sfreq = raw.info['sfreq']\n",
    "    total_dur = raw.times[-1]\n",
    "\n",
    "    intervals = sorted([(row['start_time'], row['stop_time'])\n",
    "                        for _, row in annotations_df.iterrows()])\n",
    "    clean_intervals = []\n",
    "    prev_end = 0.0\n",
    "    for st, sp in intervals:\n",
    "        if st > prev_end:\n",
    "            clean_intervals.append((prev_end, st))\n",
    "        prev_end = max(prev_end, sp)\n",
    "    if prev_end < total_dur:\n",
    "        clean_intervals.append((prev_end, total_dur))\n",
    "\n",
    "    os.makedirs(clean_eeg_path, exist_ok=True)\n",
    "    for ci_start, ci_stop in clean_intervals:\n",
    "        n_segs = int((ci_stop - ci_start) // segment_duration)\n",
    "        if n_segs <= 0:\n",
    "            continue\n",
    "        starts = [ci_start + i * segment_duration for i in range(n_segs)]\n",
    "        if max_segments_per_interval:\n",
    "            starts = random.sample(starts, min(max_segments_per_interval, len(starts)))\n",
    "        for s in starts:\n",
    "            e = s + segment_duration\n",
    "            s_smpl, e_smpl = int(s*sfreq), int(e*sfreq)\n",
    "            data = raw.get_data(start=s_smpl, stop=e_smpl)\n",
    "            fname = f\"clean_{s:.2f}_{e:.2f}.pt\"\n",
    "            torch.save(torch.from_numpy(data), os.path.join(clean_eeg_path, fname))\n",
    "\n",
    "\n",
    "def extract_random_segments_from_eeg(edf_path,\n",
    "                                     n_segments=n_random_segments,\n",
    "                                     segment_samples=segment_samples):\n",
    "    raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "\n",
    "    chans = [ch for ch in raw.ch_names if ch in channel_mapping]\n",
    "    raw.pick(chans)\n",
    "    raw.rename_channels(channel_mapping)\n",
    "\n",
    "    total_samples = raw.n_times\n",
    "    if total_samples < segment_samples:\n",
    "        raise ValueError(f\"Archivo con {total_samples} muestras < {segment_samples} requeridas.\")\n",
    "\n",
    "    os.makedirs(random_seg_path, exist_ok=True)\n",
    "    for i in range(n_segments):\n",
    "        channel = random.choice(raw.ch_names)\n",
    "        start = random.randint(0, total_samples - segment_samples)\n",
    "        stop = start + segment_samples\n",
    "        data = raw.get_data(picks=[channel], start=start, stop=stop)\n",
    "        signal = data.flatten()  # vector 1D (segment_samples,)\n",
    "        fname = f\"random_{channel}_{start}_{stop}_{i}.pt\"\n",
    "        torch.save(signal, os.path.join(random_seg_path, fname))\n",
    "\n",
    "\n",
    "def main():\n",
    "    os.makedirs(clean_eeg_path, exist_ok=True)\n",
    "    os.makedirs(random_seg_path, exist_ok=True)\n",
    "\n",
    "    csv_files = [f for f in os.listdir(data_folder) if f.endswith(csv_ext)]\n",
    "    edf_bases = {os.path.splitext(f)[0] for f in os.listdir(data_folder) if f.endswith(edf_ext)}\n",
    "    common = sorted(set(os.path.splitext(f)[0] for f in csv_files) & edf_bases)\n",
    "\n",
    "    for base in tqdm(common, desc=\"Procesando EEG\"):\n",
    "        ann_df = get_annotations_for_eeg_artifacts(data_folder, base + csv_ext)\n",
    "        edf_path = os.path.join(data_folder, base + edf_ext)\n",
    "\n",
    "        extract_clean_segments_from_eeg(edf_path, ann_df)\n",
    "        extract_random_segments_from_eeg(edf_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ad9cdb-a051-41b8-a445-3f1a0a1555c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
